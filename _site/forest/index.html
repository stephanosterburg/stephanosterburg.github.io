<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Forest Cover Type &#8211; Data Ocean</title>
<meta name="description" content="Or who cannot see the wood for the trees?">
<meta name="keywords" content="data, code, forest">

<!-- Twitter Cards -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/images/dataset-cover.jpeg">

<meta name="twitter:title" content="Forest Cover Type">
<meta name="twitter:description" content="Or who cannot see the wood for the trees?">
<meta name="twitter:creator" content="@sosterburg">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Forest Cover Type">
<meta property="og:description" content="Or who cannot see the wood for the trees?">
<meta property="og:url" content="http://localhost:4000/forest/">
<meta property="og:site_name" content="Data Ocean">





<link rel="canonical" href="http://localhost:4000/forest/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Data Ocean Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
<!-- Webfonts -->
<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- mathjax config similar to math.stackexchange -->
<!-- <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">



</head>

<body id="post" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="http://localhost:4000/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="http://localhost:4000/images/avatar.jpg" alt="Stephan Osterburg photo" class="author-photo">
					<h4>Stephan Osterburg</h4>
					<p>Computer graphics veteran with 30+ years experience on the quest to discover the world of data.</p>
				</li>
				<li><a href="http://localhost:4000/about/"><span class="btn btn-inverse">Learn More</span></a></li>
				<li>
					<a href="mailto:stephanosterburg@me.com"><i class="fa fa-fw fa-envelope"></i> Email</a>
				</li>
				<li>
					<a href="https://twitter.com/sosterburg"><i class="fa fa-fw fa-twitter"></i> Twitter</a>
				</li>
				
				
				<li>
					<a href="https://linkedin.com/in/https://www.linkedin.com/in/stephanosterburg"><i class="fa fa-fw fa-linkedin"></i> LinkedIn</a>
				</li>
				<li>
					<a href="https://github.com/https://github.com/osterburg"><i class="fa fa-fw fa-github"></i> GitHub</a>
				</li>
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="http://localhost:4000/posts/">All Posts</a></li>
				<li><a href="http://localhost:4000/tags/">All Tags</a></li>
			</ul>
		</li>
		
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->



<div class="entry-header">
  
  <div class="entry-image">
    <img src="http://localhost:4000/images/dataset-cover.jpeg" alt="Forest Cover Type">
  </div><!-- /.entry-image -->
</div><!-- /.entry-header -->


<div id="main" role="main">
  <article class="hentry">
    <header class="header-title">
      <div class="header-title-wrap">
        
          <h1 class="entry-title"><a href="http://localhost:4000/forest/" rel="bookmark" title="Forest Cover Type">Forest Cover Type</a></h1>
        
        <h2><span class="entry-date date published"><time datetime="2019-01-14T00:00:00+00:00">January 14, 2019</time></span></h2>
        
        <p class="entry-reading-time">
          <i class="fa fa-clock-o"></i>
          
Reading time ~6 minutes
        </p><!-- /.entry-reading-time -->
        
      </div><!-- /.header-title-wrap -->
    </header>
    <div class="entry-content">
      <h2 id="or-who-cannot-see-the-wood-for-the-trees">Or who cannot see the wood for the trees?</h2>

<p>Researchers at the Department of Forest Sciences at Colorado State University collected over half a million measurements from tree observations from four areas of the Roosevelt National Forest in Colorado. All observations are cartographic variables (no remote sensing) from 30-meter x 30-meter sections of forest.</p>

<p>The resulting dataset includes information on tree type, shadow coverage, distance to nearby landmarks (roads etcetera), soil type, and local topography. In total there are 55 columns/features.</p>

<h3 id="problem">Problem</h3>

<p>Can we build a model that predicts what types of trees grow in an area based on the surrounding characteristics? Like elevation, slope, distance, soil type etcetera.</p>

<h3 id="dataset">Dataset</h3>

<p>The dataset has 55 columns in total where <code class="highlighter-rouge">Wilderness_Area</code> consists of 4 dummy variables and <code class="highlighter-rouge">Soil_Tpye</code> consists of 40 dummy variables.</p>

<p>Continuous Data</p>
<ul>
  <li><code class="highlighter-rouge">Elevation</code> (in meters)</li>
  <li><code class="highlighter-rouge">Aspect</code> (in degrees azimuth<sup id="fnref:2"><a href="#fn:2" class="footnote">1</a></sup>)</li>
  <li><code class="highlighter-rouge">Slope</code> (in degrees)</li>
  <li><code class="highlighter-rouge">Horizontal_Distance_To_Hydrology</code> (Horizontal distance to nearest surface water features in meters)</li>
  <li><code class="highlighter-rouge">Horizontal_Distance_To_Roadways</code> (Horizontal distance to nearest roadway in meters)</li>
  <li><code class="highlighter-rouge">Horizontal_Distance_To_Fire_Points</code> (Horizontal distance to nearest wildfire ignition points in meters)</li>
  <li><code class="highlighter-rouge">Vertical_Distance_To_Hydrology</code> (Vertical distance to nearest surface water features in meters)</li>
  <li><code class="highlighter-rouge">Hillshade_9am</code> (Hill shade index at 9am, summer solstice. Value out of 255)</li>
  <li><code class="highlighter-rouge">Hillshade_Noon</code> (Hill shade index at noon, summer solstice. Value out of 255)</li>
  <li><code class="highlighter-rouge">Hillshade_3pm</code> (Hill shade index at 3pm, summer solstice. Value out of 255)</li>
</ul>

<p>Categorical Data</p>
<ul>
  <li><code class="highlighter-rouge">Wilderness Area</code> (4 dummy variable binary columns, 0 = absence or 1 = presence)</li>
  <li><code class="highlighter-rouge">Soil Type</code> (40 dummy variable binary columns, 0 = absence or 1 = presence)</li>
</ul>

<p>The target variable <code class="highlighter-rouge">Cover_Type</code> is defined as an integer value between <code class="highlighter-rouge">1</code> and <code class="highlighter-rouge">7</code>, with the following key:</p>

<ol>
  <li>Spruce/Fir.</li>
  <li>Lodgepole Pine.</li>
  <li>Ponderosa Pine.</li>
  <li>Cottonwood/Willow</li>
  <li>Aspen</li>
  <li>Douglas-fir</li>
  <li>Krummholz</li>
</ol>

<h3 id="approach">Approach</h3>

<h4 id="eda">EDA</h4>

<p>The first step with every dataset is to do an <code class="highlighter-rouge">Exploratory Data Analysis</code> (EDA). What kind of data do we have? Text or numerical (continues or categorical)? Do we have missing data, or just merely wrong data — values which do not make any sense in the given context, i.e., 9999.</p>

<p>Because of the sheer number of soil types and wilderness areas I had a look at them first. Luckily, the researchers here were efficient in the sense that they document everything meticulously. Everything we need to know with a detailed description can be found online<sup id="fnref:3"><a href="#fn:3" class="footnote">2</a></sup>.</p>

<p>From that document, we can find out that</p>
<blockquote>
  <p>This study area includes four wilderness areas located in the
   Roosevelt National Forest of northern Colorado.  These areas
   represent forests with minimal human-caused disturbances,
   so that existing forest cover types are more a result of 
   ecological processes rather than forest management practices.</p>
</blockquote>

<p>Not that this is of any importance for our data exploration or to make a prediction, but I found it interesting to read. Because it makes you think about what kind of implications your result can potentially have.</p>

<p>However, what we want to find out is how the data is distributed by <code class="highlighter-rouge">Cover_Type</code>. Here I created a <code class="highlighter-rouge">seaborn.countplot</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tmpList</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">soil_df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">tmpList</span> <span class="o">+=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">c</span><span class="p">)]</span> <span class="o">*</span> <span class="n">soil_df</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">se</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">tmpList</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">'Soil_Types'</span><span class="p">]</span> <span class="o">=</span> <span class="n">se</span><span class="o">.</span><span class="n">values</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Soil_Types'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'Cover_Type'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Number of Observation by Cover Type'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div></div>

<figure>
    
    <a href="/images/SoilType.png"><img src="/images/SoilType.png" alt="" /></a>
    
    <figcaption></figcaption>
</figure>

<p>Looking more closely at the data we can find that the top 5 soil types count for more than 50% of the measurements in the collected data.</p>

<p>Unlike categorical data, the continues data is even more interesting to investigate. The questions we want to find answers for are</p>

<ul>
  <li>Do we need to scale/normalise the continuous data?</li>
  <li>What about skewness/kurtosis?</li>
  <li>Does it matter if the data is in meter, degree or index?</li>
</ul>

<figure>
    
    <a href="/images/ContinuesData.png"><img src="/images/ContinuesData.png" alt="" /></a>
    
    <figcaption></figcaption>
</figure>

<h3 id="feature-selection">Feature Selection</h3>

<p>There are several ways to explore what features we need to keep around to make our prediction. The labour intensive workflow and the much quicker workflow - what I would like to call the “blindfolded method”. For the purpose of gaining more inside, I choose to do both.</p>

<p>In the first workflow, I used several classifiers from the <code class="highlighter-rouge">sklearn.ensemble</code> Library. These are, <code class="highlighter-rouge">AdaBoostClassifier</code>,  <code class="highlighter-rouge">RandomForestClassifier</code>, <code class="highlighter-rouge">GradientBoostingClassifier</code> and <code class="highlighter-rouge">ExtraTreeClassifier</code>. All these classifiers have one thing in common, which is the attribute <code class="highlighter-rouge">feature_importances_</code>, which returns the feature importance (the higher the value, the more important the feature).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create an empty dataframe to hold our findings for feature_importances_
</span><span class="n">ranking_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>

<span class="n">RFC_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">RFC_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">importances</span> <span class="o">=</span> <span class="n">RFC_model</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">importances</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Get feature name
</span><span class="n">rfc_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">f</span><span class="p">]]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
<span class="n">ranking_df</span><span class="p">[</span><span class="s">'RFC'</span><span class="p">]</span> <span class="o">=</span> <span class="n">rfc_list</span>

<span class="c1"># Get feature importance
</span><span class="n">rfci_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">importances</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">f</span><span class="p">]]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
<span class="n">ranking_df</span><span class="p">[</span><span class="s">'RFC importance'</span><span class="p">]</span> <span class="o">=</span> <span class="n">rfci_list</span>
</code></pre></div></div>

<p>The result was a pandas data frame with all features from the dataset in order of importance, which allows us to pick the best features. Interestingly, <code class="highlighter-rouge">RandomForestClassifier</code> and <code class="highlighter-rouge">ExtraTreeClassifier</code> had the most similar results. Other findings from that list were,</p>

<ul>
  <li><code class="highlighter-rouge">Gradian Boosting</code> shows similar names just in a different order compared to <code class="highlighter-rouge">Random Forest</code> and <code class="highlighter-rouge">Extra Tree</code>.</li>
  <li><code class="highlighter-rouge">AdaBoost</code> on the other hand shows an exciting and unique result. The top 8 features alone are enough to make a good class prediction. Compared to all the other classifiers, here we have <code class="highlighter-rouge">Wilderness_Area4</code> on above <code class="highlighter-rouge">Elevation</code> in the list.</li>
  <li><code class="highlighter-rouge">Elevation</code> dominates in all classifiers with a range of <code class="highlighter-rouge">18-25%</code>, up to <code class="highlighter-rouge">65%</code> in <code class="highlighter-rouge">GBC</code>.</li>
  <li><code class="highlighter-rouge">Hillshade</code> features are seen in the top 20 in 3 out of 4 classifiers. <code class="highlighter-rouge">Random Forest</code> and <code class="highlighter-rouge">Extra Tree Classifier</code> show <code class="highlighter-rouge">Hillshade</code> features having similar ranges.</li>
  <li><code class="highlighter-rouge">Horizontal_Distance_To_Hydrology</code> and <code class="highlighter-rouge">Vertical_Distance_To_Hydrology</code> are in all classifiers in the top 10.</li>
  <li><code class="highlighter-rouge">Horizontal_Distance_To_Roadways</code> and <code class="highlighter-rouge">Horizontal_Distance_To_Fire_Points</code> are represented at the top 3 out of 4 classifiers.</li>
  <li><code class="highlighter-rouge">Aspect</code> and <code class="highlighter-rouge">Slope</code> also show up in the top 20 across all classifiers, with the exception of Gradian Boosting Slope which isn’t in the top 20.</li>
  <li>In regards to <code class="highlighter-rouge">Soil_Type</code>, it is hard to find some commonality. Here I choose to select: <code class="highlighter-rouge">Soil_Type2</code>, <code class="highlighter-rouge">Soil_Type4</code>, <code class="highlighter-rouge">Soil_Type10</code>, <code class="highlighter-rouge">Soil_Type22</code>, <code class="highlighter-rouge">Soil_Type23</code> and <code class="highlighter-rouge">Soil_Type39</code>.</li>
</ul>

<p>The question I asked myself at this point is, was the time wisely spend? After all, it took almost 20 minutes to calculate. One advantage this approach has is, we know our selected features.</p>

<p>The other approach we can choose is using <code class="highlighter-rouge">PCA</code> (Principal Component Analysis) from sklearn.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'Cover_Type'</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'Cover_Type'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
</code></pre></div></div>

<p>The big advantage to this is the short processing time. However, the drawback, we are losing any knowledge regarding our features. Is that important? Possibly.</p>

<p>As you can see in the code snippet above, I opted to scale the features. Researching that topic, I found that there is a multitude of approaches, some use a combination of <code class="highlighter-rouge">StandardScaler</code>, <code class="highlighter-rouge">MinMaxScaler</code> and <code class="highlighter-rouge">Normalizer</code> method and others just picked one of the methods for scaling, centring, normalisation, binarisation and imputation the <code class="highlighter-rouge">sklearn.preprocessing</code> module. Some just scale only the continuous features and not the categorical, etcetera. The list of possibilities goes on. For now, I just used the most straightforward way.</p>

<h3 id="evaluate-model">Evaluate Model</h3>

<p>By hand selecting our features, we get an <code class="highlighter-rouge">accuracy of 92.23%</code> and an <code class="highlighter-rouge">f1_score of 86.74%</code> using cross validation. In contrast, <code class="highlighter-rouge">PCA</code> has an <code class="highlighter-rouge">accuracy of 90.72%</code> and an <code class="highlighter-rouge">f1_score of 84.44%</code>. Is that a big enough difference to justify the time spent to find our features? Maybe.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_pca</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s">'distance'</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s">'accuracy'</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">f1_score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s">'f1_macro'</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># predict
</span><span class="n">predict</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># calculating accuracy
</span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predict</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'KNeighbors Classifier model'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy: {:.2f}</span><span class="si">%</span><span class="s">'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>

<span class="n">knn_classification_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predict</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">knn_classification_report</span><span class="p">)</span>
</code></pre></div></div>

<figure>
    
    <a href="/images/CrossValidation.png"><img src="/images/CrossValidation.png" alt="" /></a>
    
    <figcaption></figcaption>
</figure>

<p>To test how accurate we can predict the <code class="highlighter-rouge">Cover_Type</code> I used the <code class="highlighter-rouge">KNeighborsClassifier</code> from sklearn, and we got an accuracy of <code class="highlighter-rouge">91.02%</code>. That is great.</p>

<h2 id="conclusion">Conclusion</h2>

<p><strong>Yes</strong>, we can build a model that predicts what types of trees grow in an area based on the surrounding characteristics.</p>

<h2 id="final-thought">Final Thought</h2>

<p>We can use sklearn’s <code class="highlighter-rouge">GridSearchCV</code> to find our features (exhaustive search over specified parameter values for an estimator). Moreover, we should make use of sklearn’s <code class="highlighter-rouge">Pipeline</code> functionality to write clean and manageable code.</p>

<p>One last question, could we use clustering to make our prediction?</p>

<h5 id="footnotes">Footnotes</h5>

<noscript><pre>404: Not Found
</pre></noscript>
<script src="https://gist.github.com/mmistakes/6589546.js"> </script>

<div class="footnotes">
  <ol>
    <li id="fn:2">
      <p><a href="https://en.wikipedia.org/wiki/Azimuth">https://en.wikipedia.org/wiki/Azimuth</a> <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p><a href="https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info">https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info</a> <a href="#fnref:3" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

      <footer class="entry-meta">
        <span class="entry-tags"><a href="http://localhost:4000/tags/#data" title="Pages tagged data" class="tag"><span class="term">data</span></a><a href="http://localhost:4000/tags/#code" title="Pages tagged code" class="tag"><span class="term">code</span></a><a href="http://localhost:4000/tags/#forest" title="Pages tagged forest" class="tag"><span class="term">forest</span></a></span>
        
        <div class="social-share">
  <ul class="socialcount socialcount-small inline-list">
    <li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/forest/" title="Share on Facebook"><span class="count"><i class="fa fa-facebook-square"></i> Like</span></a></li>
    <li class="twitter"><a href="https://twitter.com/intent/tweet?text=http://localhost:4000/forest/" title="Share on Twitter"><span class="count"><i class="fa fa-twitter-square"></i> Tweet</span></a></li>
    <li class="googleplus"><a href="https://plus.google.com/share?url=http://localhost:4000/forest/" title="Share on Google Plus"><span class="count"><i class="fa fa-google-plus-square"></i> +1</span></a></li>
  </ul>
</div><!-- /.social-share -->
      </footer>
    </div><!-- /.entry-content -->
    
    <div class="read-more">
  
    <div class="read-more-header">
      <a href="http://localhost:4000/mapping_data_with_folium/" class="read-more-btn">Read More</a>
    </div><!-- /.read-more-header -->
    <div class="read-more-content">
      <h3><a href="http://localhost:4000/text_classification_part_2/" title="Text Classification (Part 2)">Text Classification (Part 2)</a></h3>
      <p>Fake News <a href="http://localhost:4000/text_classification_part_2/">Continue reading</a></p>
    </div><!-- /.read-more-content -->
  
  <div class="read-more-list">
    
      <div class="list-item">
        <h4><a href="http://localhost:4000/text_classification_part_1/" title="Text Classification (Part 1)">Text Classification (Part 1)</a></h4>
        <span>Published on April 02, 2019</span>
      </div><!-- /.list-item -->
    
      <div class="list-item">
        <h4><a href="http://localhost:4000/an_introductio_to_diffusion_maps/" title="A short introduction to Diffusion Maps">A short introduction to Diffusion Maps</a></h4>
        <span>Published on February 23, 2019</span>
      </div><!-- /.list-item -->
    
  </div><!-- /.read-more-list -->
</div><!-- /.read-more -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2019 Stephan Osterburg. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="https://mademistakes.com/work/hpstr-jekyll-theme/" rel="nofollow">HPSTR Theme</a>.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>





</body>
</html>
