<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Deep Learning and Art Images &#8211; Data Ocean</title>
<meta name="description" content="An interpretation of the paper">
<meta name="keywords" content="data, code, art, deep learning, beginner">

<!-- Twitter Cards -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/images/GoogleArt_cropped.png">

<meta name="twitter:title" content="Deep Learning and Art Images">
<meta name="twitter:description" content="An interpretation of the paper">
<meta name="twitter:creator" content="@sosterburg">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep Learning and Art Images">
<meta property="og:description" content="An interpretation of the paper">
<meta property="og:url" content="http://localhost:4000/deep_learning_art_images/">
<meta property="og:site_name" content="Data Ocean">





<link rel="canonical" href="http://localhost:4000/deep_learning_art_images/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Data Ocean Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
<!-- Webfonts -->
<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- mathjax config similar to math.stackexchange -->
<!-- <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">



</head>

<body id="post" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="http://localhost:4000/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="http://localhost:4000/images/avatar.jpg" alt="Stephan Osterburg photo" class="author-photo">
					<h4>Stephan Osterburg</h4>
					<p>Computer graphics veteran with 30+ years experience on the quest to discover the world of data.</p>
				</li>
				<li><a href="http://localhost:4000/about/"><span class="btn btn-inverse">Learn More</span></a></li>
				<li>
					<a href="mailto:stephanosterburg@me.com"><i class="fa fa-fw fa-envelope"></i> Email</a>
				</li>
				<li>
					<a href="https://twitter.com/sosterburg"><i class="fa fa-fw fa-twitter"></i> Twitter</a>
				</li>
				
				
				<li>
					<a href="https://linkedin.com/in/https://www.linkedin.com/in/stephanosterburg"><i class="fa fa-fw fa-linkedin"></i> LinkedIn</a>
				</li>
				<li>
					<a href="https://github.com/https://github.com/osterburg"><i class="fa fa-fw fa-github"></i> GitHub</a>
				</li>
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="http://localhost:4000/posts/">All Posts</a></li>
				<li><a href="http://localhost:4000/tags/">All Tags</a></li>
			</ul>
		</li>
		
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->



<div class="entry-header">
  
  <div class="entry-image">
    <img src="http://localhost:4000/images/GoogleArt_cropped.png" alt="Deep Learning and Art Images">
  </div><!-- /.entry-image -->
</div><!-- /.entry-header -->


<div id="main" role="main">
  <article class="hentry">
    <header class="header-title">
      <div class="header-title-wrap">
        
          <h1 class="entry-title"><a href="http://localhost:4000/deep_learning_art_images/" rel="bookmark" title="Deep Learning and Art Images">Deep Learning and Art Images</a></h1>
        
        <h2><span class="entry-date date published"><time datetime="2019-02-09T00:00:00+00:00">February 09, 2019</time></span></h2>
        
        <p class="entry-reading-time">
          <i class="fa fa-clock-o"></i>
          
Reading time ~3 minutes
        </p><!-- /.entry-reading-time -->
        
      </div><!-- /.header-title-wrap -->
    </header>
    <div class="entry-content">
      <p>At <a href="https://www.kaggle.com">kaggle</a> we can find a dataset containing a collection of art images of google images, yandex images and from <a href="http://rusmuseumvrm.ru/collections/?lang=en">The Virtual Russian Museum</a>. The dataset has about 9000 images with five categories:</p>
<ol>
  <li>Drawings and Watercolors</li>
  <li>Paintings</li>
  <li>Sculpture</li>
  <li>Graphic Art</li>
  <li>Iconography (old Russian art)</li>
</ol>

<p>Because it is a classification problem, I wanted to use my newly learned knowledge in deep learning and convolutional neural networks (CNN). However, first things first, the downloaded zip file has two more zip files, which it turns out are somewhat similar in context but not quiet. So I decided to combine the two into one dataset.</p>

<h2 id="approach">Approach</h2>

<p>When I started to research how to tackle the issue for image classification, I found three possible options:</p>
<ul>
  <li><code class="highlighter-rouge">train_test_split</code>, we have to create the train and test data ourselves.</li>
  <li><code class="highlighter-rouge">flow_from_dataframe</code>, we need to create first the dataframe ourselves.</li>
  <li><code class="highlighter-rouge">flow_from_dictonary</code>, here we don’t need to do any extra work.</li>
</ul>

<p>I, as you may guessed it already, opted for the later.</p>

<h2 id="how-deep-is-too-deep">How deep is too deep?</h2>

<p>To answer that question, here we need to know one fact first. I am working on a MacBook Pro (2015) with a 2.2 GHz Intel Core i7 processor and 16GB of RAM.</p>

<p>So, how deep is too deep? How many layers can I run on my computer without feeling the pain? To find out I approached it very gingerly, step by step. Or shall I say layer by layer?</p>

<p>For the first try, I had only a few layers, which helped with the computation time. However, the result showed a test accuracy of less than 50%.</p>

<noscript><pre>400: Invalid request
</pre></noscript>
<script src="https://gist.github.com/8011d4e50fc6e22d9eb73b7763124003.js"> </script>

<p>To improve the test accuracy, I kept adding layers. I ended up adding several more layers, including <code class="highlighter-rouge">Dropout</code> layers to help to avoid over-fitting.</p>

<noscript><pre>400: Invalid request
</pre></noscript>
<script src="https://gist.github.com/57eff9c73a1f613847a2985a86c499fa.js"> </script>

<p>With the simple sequential model the computational time wasn’t too bad but with the  model, seen above, the time went up from several minutes per epochs to nearly 30 minutes per epochs.</p>

<h3 id="epochsbatch_size">epochs/batch_size</h3>

<p>An <code class="highlighter-rouge">epochs</code> is an iteration over the entire provided data; for example, if we have <code class="highlighter-rouge">epochs=25</code> we iterate 25 times over the data. The <code class="highlighter-rouge">batch_size</code> is the number of samples that will propagate through the network, by default 32. In our case where we have about 8000 images in the training set, we have 250 batches per epochs.</p>

<p>The question is, do we decrease the batch_size to 16 or increase the number to 64? If we decrease the number, we have 500 batches vs 125 batches if we increase the number. Large batch size result in faster processing time and vice versa. In regards to epochs, the model improves with more but only to a point. They start to plateau in accuracy as they converge.</p>

<h2 id="pre-trained-network">Pre-Trained Network</h2>

<p>To improve not only the accuracy but also the processing time (so I hoped), I decided to use a pre-trained network. There are a few we can choose from, for example <a href="https://keras.io/applications/#vgg16">VGG16</a>, <a href="https://keras.io/applications/#vgg19">VGG19</a>, <a href="https://keras.io/applications/#inceptionv3">InceptionV3</a>, and <a href="https://keras.io/applications/#resnet50">ResNet50</a> etcetera. I resorted to the <a href="https://arxiv.org/abs/1409.1556">VGG</a> model to keep it simple for the time being.</p>

<p><strong>VGG</strong> is a convolutional neural network model for image recognition proposed by the <strong>Visual Geometry Group in the University of Oxford</strong>, where <em>VGG16</em> refers to a VGG model with 16 weight layers, and <em>VGG19</em> refers to a VGG model with 19 weight layers.</p>

<p>Because we have an already trained model, all we have to do is add at least two more layers (<code class="highlighter-rouge">Flatten</code> and the output <code class="highlighter-rouge">Dense</code> layer) to test what the pre-trained network can do with our dataset. In my case I ended up adding six layers in total:</p>

<noscript><pre>400: Invalid request
</pre></noscript>
<script src="https://gist.github.com/2960515a509218482bbbff1a45add65c.js"> </script>

<p>Now, the accuracy improved to 96.68%, up &gt;5% from my previous model, but not the processing time.</p>

<h2 id="aws">AWS</h2>

<p>In the end, it took several hours to run the model. Moreover, it makes it even more painful if you forget to change your default setting on your MacBook and the computer goes into sleep mode, and nothing get processed at all.</p>

<p>To free up the computer I resorted to - welcome - <a href="https://www.paperspace.com">paperspace</a>.</p>

<p>Which allows me to prototype locally (prove of concept) and compute in the cloud.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Use where you can pre-trained networks and if you are using large data use cloud services.</p>


      <footer class="entry-meta">
        <span class="entry-tags"><a href="http://localhost:4000/tags/#data" title="Pages tagged data" class="tag"><span class="term">data</span></a><a href="http://localhost:4000/tags/#code" title="Pages tagged code" class="tag"><span class="term">code</span></a><a href="http://localhost:4000/tags/#art" title="Pages tagged art" class="tag"><span class="term">art</span></a><a href="http://localhost:4000/tags/#deep learning" title="Pages tagged deep learning" class="tag"><span class="term">deep learning</span></a><a href="http://localhost:4000/tags/#beginner" title="Pages tagged beginner" class="tag"><span class="term">beginner</span></a></span>
        
        <div class="social-share">
  <ul class="socialcount socialcount-small inline-list">
    <li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/deep_learning_art_images/" title="Share on Facebook"><span class="count"><i class="fa fa-facebook-square"></i> Like</span></a></li>
    <li class="twitter"><a href="https://twitter.com/intent/tweet?text=http://localhost:4000/deep_learning_art_images/" title="Share on Twitter"><span class="count"><i class="fa fa-twitter-square"></i> Tweet</span></a></li>
    <li class="googleplus"><a href="https://plus.google.com/share?url=http://localhost:4000/deep_learning_art_images/" title="Share on Google Plus"><span class="count"><i class="fa fa-google-plus-square"></i> +1</span></a></li>
  </ul>
</div><!-- /.social-share -->
      </footer>
    </div><!-- /.entry-content -->
    
    <div class="read-more">
  
    <div class="read-more-header">
      <a href="http://localhost:4000/an_introductio_to_diffusion_maps/" class="read-more-btn">Read More</a>
    </div><!-- /.read-more-header -->
    <div class="read-more-content">
      <h3><a href="http://localhost:4000/an_introductio_to_diffusion_maps/" title="An Introduction to Diffusion Maps">An Introduction to Diffusion Maps</a></h3>
      <p>An interpretation of the paper <a href="http://localhost:4000/an_introductio_to_diffusion_maps/">Continue reading</a></p>
    </div><!-- /.read-more-content -->
  
  <div class="read-more-list">
    
      <div class="list-item">
        <h4><a href="http://localhost:4000/forest/" title="Forest Cover Type">Forest Cover Type</a></h4>
        <span>Published on January 14, 2019</span>
      </div><!-- /.list-item -->
    
      <div class="list-item">
        <h4><a href="http://localhost:4000/mapping_data_with_folium/" title="Mapping Data with folium">Mapping Data with folium</a></h4>
        <span>Published on December 07, 2018</span>
      </div><!-- /.list-item -->
    
  </div><!-- /.read-more-list -->
</div><!-- /.read-more -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2019 Stephan Osterburg. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="https://mademistakes.com/work/hpstr-jekyll-theme/" rel="nofollow">HPSTR Theme</a>.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>





</body>
</html>
