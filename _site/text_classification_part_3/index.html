<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Text Classification (Part 3) &#8211; Data Ocean</title>
<meta name="description" content="Fake News">
<meta name="keywords" content="data, code, content">

<!-- Twitter Cards -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/images/Newstand_part3.jpg">

<meta name="twitter:title" content="Text Classification (Part 3)">
<meta name="twitter:description" content="Fake News">
<meta name="twitter:creator" content="@sosterburg">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Text Classification (Part 3)">
<meta property="og:description" content="Fake News">
<meta property="og:url" content="http://localhost:4000/text_classification_part_3/">
<meta property="og:site_name" content="Data Ocean">





<link rel="canonical" href="http://localhost:4000/text_classification_part_3/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Data Ocean Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
<!-- Webfonts -->
<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- mathjax config similar to math.stackexchange -->
<!-- <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">



</head>

<body id="post" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="http://localhost:4000/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="http://localhost:4000/images/avatar.jpg" alt="Stephan Osterburg photo" class="author-photo">
					<h4>Stephan Osterburg</h4>
					<p>Computer graphics veteran with 30+ years experience on the quest to discover the world of data.</p>
				</li>
				<li><a href="http://localhost:4000/about/"><span class="btn btn-inverse">Learn More</span></a></li>
				<li>
					<a href="mailto:stephanosterburg@me.com"><i class="fa fa-fw fa-envelope"></i> Email</a>
				</li>
				<li>
					<a href="https://twitter.com/sosterburg"><i class="fa fa-fw fa-twitter"></i> Twitter</a>
				</li>
				
				
				<li>
					<a href="https://linkedin.com/in/https://www.linkedin.com/in/stephanosterburg"><i class="fa fa-fw fa-linkedin"></i> LinkedIn</a>
				</li>
				<li>
					<a href="https://github.com/https://github.com/osterburg"><i class="fa fa-fw fa-github"></i> GitHub</a>
				</li>
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="http://localhost:4000/posts/">All Posts</a></li>
				<li><a href="http://localhost:4000/tags/">All Tags</a></li>
			</ul>
		</li>
		
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->



<div class="entry-header">
  
  <div class="entry-image">
    <img src="http://localhost:4000/images/Newstand_part3.jpg" alt="Text Classification (Part 3)">
  </div><!-- /.entry-image -->
</div><!-- /.entry-header -->


<div id="main" role="main">
  <article class="hentry">
    <header class="header-title">
      <div class="header-title-wrap">
        
          <h1 class="entry-title"><a href="http://localhost:4000/text_classification_part_3/" rel="bookmark" title="Text Classification (Part 3)">Text Classification (Part 3)</a></h1>
        
        <h2><span class="entry-date date published"><time datetime="2019-04-07T00:00:00+01:00">April 07, 2019</time></span></h2>
        
        <p class="entry-reading-time">
          <i class="fa fa-clock-o"></i>
          
Reading time ~4 minutes
        </p><!-- /.entry-reading-time -->
        
      </div><!-- /.header-title-wrap -->
    </header>
    <div class="entry-content">
      <h2 id="using-big-data">Using Big Data</h2>

<p>The dataset used for that project is an already <a href="https://github.com/several27/FakeNewsCorpus">polished and fairly large corpus</a> by Maciej Szpakowski.</p>

<blockquote>
  <p>This is an open source dataset composed of millions of news articles mostly scraped from a curated list of 1001 domains from http://www.opensources.co/. Because the list does not contain any reliable websites, additionally NYTimes and Webhose English News Articles articles have been included to balance the classes better. The dataset is still work in progress, and for now, the public version includes only 9,408,908 articles (745 out of 1001 domains).</p>
</blockquote>

<p>The available data has more than 26GB on disk when we unzip the file and more than 75GB in RAM using pandas. For that reason, I considered using <a href="https://dask.org/">dask</a>. However, loading the CSV file ended in a ParserError (<code class="highlighter-rouge">Error tokenizing data. C error: EOF inside string starting at row 63</code>) and apparently, this is a <a href="https://stackoverflow.com/q/45752805/5983691">known problem</a> with dask’s read_csv if the file contains a newline character between quotes.</p>

<p>To read the CSV file with pandas, the same row (63) ended in a <code class="highlighter-rouge">_csv.Error: field larger than field limit (131072)</code>. To address that error we have to first increase the <code class="highlighter-rouge">csv.field_size_limit</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># _csv.Error: field larger than field limit (131072)
# https://stackoverflow.com/a/15063941/5983691
</span><span class="k">def</span> <span class="nf">csv_field_limit</span><span class="p">():</span>
    <span class="n">maxInt</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span>
    <span class="n">decrement</span> <span class="o">=</span> <span class="bp">True</span>

    <span class="k">while</span> <span class="n">decrement</span><span class="p">:</span>
        <span class="c1"># decrease the maxInt value by factor 10
</span>        <span class="c1"># as long as the OverflowError occurs.
</span>        <span class="n">decrement</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">csv</span><span class="o">.</span><span class="n">field_size_limit</span><span class="p">(</span><span class="n">maxInt</span><span class="p">)</span>
        <span class="k">except</span> <span class="nb">OverflowError</span><span class="p">:</span>
            <span class="n">maxInt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">maxInt</span><span class="o">/</span><span class="mi">10</span><span class="p">)</span>
            <span class="n">decrement</span> <span class="o">=</span> <span class="bp">True</span>
</code></pre></div></div>

<p>The dataset is not huge but is also larger than we’d like to manage on a laptop, especially if we value interactivity. In any case, let’s have a look at the first 100 rows to see what we have and determine what features we can drop and others we want to keep.</p>

<figure>
    
    <a href="/images/BigDataTable.png"><img src="/images/BigDataTable.png" alt="" /></a>
    
    <figcaption></figcaption>
</figure>

<p>To fix the <code class="highlighter-rouge">EOF</code> problem, we can load in the dataset in chunks and loop that way through the dataset. Loading the CSV file in chunks helps but it is impractical to get a full picture of our data. With dask, we can utilise all the cores we have on our laptop.</p>

<p style="text-align: center;"><img src="/images/DaskClient.png" alt="Content by URL Count" /></p>

<p>Now we can get a quick view of what categories and how many we have in our dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">categories</span> <span class="o">=</span> <span class="n">ddf</span><span class="o">.</span><span class="n">category</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="n">categories</span>
</code></pre></div></div>

<p style="text-align: center;"><img src="/images/BigDataCategories.png" alt="Content by URL Count" /></p>

<p>As we can see we need to do some cleaning. We have some oddly named categories and I also checked for null values. From our data exploration, we have a few handy functions to clean the data we will use here again. For example, remove all digits, HTML strings and stopwords from our text and to lemmatise the words.</p>

<p>To send the data to separate processes for processing, we can configure dask’s scheduler and set it globally. This option is useful when operating on pure Python objects like strings.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="s">'processes'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="parquet">Parquet</h2>

<p>To save disk space dask encourages dataframes (pandas) users like us to use <a href="https://parquet.apache.org/">Parquet</a>. It is a columnar binary format that is easy to split into multiple files (easier for parallel loading) and is generally much simpler to deal with than compared to HDF5 a popular choice for Pandas users with high-performance needs. It is also a common format used by other big data systems like <a href="https://spark.apache.org/">Apache Spark</a> and <a href="https://impala.apache.org/">Apache Impala</a>.</p>

<p>For data-sets too big to fit conveniently into memory, like ours, we want to read it in line by line or iterate through the row-groups in a similar way to reading by chunks from CSV with pandas. For the latter, <a href="https://fastparquet.readthedocs.io/en">fastparquet</a> makes it possible to do that using <a href="https://fastparquet.readthedocs.io/en/latest/api.html#fastparquet.ParquetFile.iter_row_groups">iter_row_groups API</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pf</span> <span class="o">=</span> <span class="n">ParquetFile</span><span class="p">(</span><span class="s">'myfile.parq'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">pf</span><span class="o">.</span><span class="n">iter_row_groups</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1"># process sub-data-frame df
</span></code></pre></div></div>

<p>As an alternative option, I found the <a href="http://turicas.info/rows/">rows package</a> by  Álvaro Justen.</p>

<h2 id="deep-learning-model">Deep Learning Model</h2>

<p>For the initial model, I choose to create a Convolutional neural network (CNN)  using keras:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
	<span class="n">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
		<span class="n">padding</span><span class="o">=</span><span class="s">'valid'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
	<span class="n">GlobalMaxPooling1D</span><span class="p">(),</span>
	<span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dims</span><span class="p">),</span>
	<span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
	<span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">)</span>
	<span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</code></pre></div></div>

<p>Also, to be able to read in the data I needed to create a custom generator to process each line in the CSV file:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_generator_process_line</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
    <span class="n">embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">max_words</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">()[:</span><span class="n">max_words</span><span class="p">]):</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">glove</span><span class="p">:</span>
            <span class="n">embedding</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">glove</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">line</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">Generator</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="c1"># skip header
</span>            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
                <span class="nb">next</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

            <span class="n">batch_i</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">batch_embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_words</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
            <span class="n">batch_category</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

            <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
                <span class="n">embedding</span><span class="p">,</span> <span class="n">category</span> <span class="o">=</span> <span class="n">_generator_process_line</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>

                <span class="k">if</span> <span class="p">(</span><span class="n">batch_i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">batch_size</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="n">batch_embedding</span><span class="p">,</span> <span class="n">batch_category</span>

                    <span class="n">batch_embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_words</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
                    <span class="n">batch_category</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                    <span class="n">batch_i</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">batch_embedding</span><span class="p">[</span><span class="n">batch_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">embedding</span>
                    <span class="n">batch_category</span><span class="p">[</span><span class="n">batch_i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">category</span>
                    <span class="n">batch_i</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div>

<p>The following code snippet trains the model on data generated batch-by-batch by the python generator above.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s">'/gpu:0'</span><span class="p">):</span>
	<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span><span class="n">Generator</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">),</span>
					<span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">train_size</span><span class="o">//</span><span class="n">batch_size</span><span class="p">,</span>
					<span class="n">validation_data</span><span class="o">=</span><span class="n">Generator</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">),</span>
					<span class="n">validation_steps</span><span class="o">=</span><span class="n">valid_size</span><span class="o">//</span><span class="n">batch_size</span><span class="p">,</span>
					<span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>Our model returns a near perfect accuracy score of 97.83%, and if we are looking at the training and validation results, we might be inclined to save the keras model into a single HDF5 file at each epoch. That way we can save the best possible model. We probably could have stopped at the third epoch and saved us a lot of time.</p>

<p style="text-align: center;"><img src="/images/training_validation_results.png" alt="Content by URL Count" /></p>

<h2 id="gpu">GPU</h2>

<p>You may notice the <code class="highlighter-rouge">with</code>-statement and recall that I am working on a laptop. To train the model on the laptop is not manageable. To be able to train the model I used <a href="https://www.paperspace.com/gradient">paperspace’s</a> gradient service, which includes jupyter notebooks, a job runner, and a python module to run any code on Paperspace GPU cloud. The gradient machine I created is a Quadro P4000 with 8CPU’s and 30GB RAM. One epoch needed about 45 minutes to calculate.</p>

<h2 id="what-next">What next?</h2>

<p>Create two more keras models, one which focuses on its “content” and the other model on its “context”. Furthermore, be able to predict what type of news article do we have - reliable or unreliable. And as a bonus, I like to add linguistic analysis.</p>

<p>Finally, build a <a href="https://dash.plot.ly/">dashboard</a>.</p>

      <footer class="entry-meta">
        <span class="entry-tags"><a href="http://localhost:4000/tags/#data" title="Pages tagged data" class="tag"><span class="term">data</span></a><a href="http://localhost:4000/tags/#code" title="Pages tagged code" class="tag"><span class="term">code</span></a><a href="http://localhost:4000/tags/#content" title="Pages tagged content" class="tag"><span class="term">content</span></a></span>
        
        <div class="social-share">
  <ul class="socialcount socialcount-small inline-list">
    <li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/text_classification_part_3/" title="Share on Facebook"><span class="count"><i class="fa fa-facebook-square"></i> Like</span></a></li>
    <li class="twitter"><a href="https://twitter.com/intent/tweet?text=http://localhost:4000/text_classification_part_3/" title="Share on Twitter"><span class="count"><i class="fa fa-twitter-square"></i> Tweet</span></a></li>
    <li class="googleplus"><a href="https://plus.google.com/share?url=http://localhost:4000/text_classification_part_3/" title="Share on Google Plus"><span class="count"><i class="fa fa-google-plus-square"></i> +1</span></a></li>
  </ul>
</div><!-- /.social-share -->
      </footer>
    </div><!-- /.entry-content -->
    
    <div class="read-more">
  
    <div class="read-more-header">
      <a href="http://localhost:4000/text_classification_part_2/" class="read-more-btn">Read More</a>
    </div><!-- /.read-more-header -->
    <div class="read-more-content">
      <h3><a href="http://localhost:4000/text_classification_part_2/" title="Text Classification (Part 2)">Text Classification (Part 2)</a></h3>
      <p>Fake News <a href="http://localhost:4000/text_classification_part_2/">Continue reading</a></p>
    </div><!-- /.read-more-content -->
  
  <div class="read-more-list">
    
      <div class="list-item">
        <h4><a href="http://localhost:4000/text_classification_part_1/" title="Text Classification (Part 1)">Text Classification (Part 1)</a></h4>
        <span>Published on April 02, 2019</span>
      </div><!-- /.list-item -->
    
      <div class="list-item">
        <h4><a href="http://localhost:4000/an_introductio_to_diffusion_maps/" title="A short introduction to Diffusion Maps">A short introduction to Diffusion Maps</a></h4>
        <span>Published on February 23, 2019</span>
      </div><!-- /.list-item -->
    
  </div><!-- /.read-more-list -->
</div><!-- /.read-more -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2019 Stephan Osterburg. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="https://mademistakes.com/work/hpstr-jekyll-theme/" rel="nofollow">HPSTR Theme</a>.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>





</body>
</html>
