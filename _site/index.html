<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Thoughts &#8211; Data Ocean</title>
<meta name="description" content="Describe this nonsense.">
<meta name="keywords" content="Jekyll, theme, themes, responsive, blog, modern">

<!-- Twitter Cards -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/images/background.jpeg">

<meta name="twitter:title" content="Thoughts">
<meta name="twitter:description" content="Describe this nonsense.">
<meta name="twitter:creator" content="@sosterburg">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Thoughts">
<meta property="og:description" content="Describe this nonsense.">
<meta property="og:url" content="http://localhost:4000/">
<meta property="og:site_name" content="Data Ocean">





<link rel="canonical" href="http://localhost:4000/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Data Ocean Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
<!-- Webfonts -->
<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">



</head>

<body id="post-index" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="http://localhost:4000/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="http://localhost:4000/images/avatar.jpg" alt="Stephan Osterburg photo" class="author-photo">
					<h4>Stephan Osterburg</h4>
					<p>Computer graphics veteran with 30+ years experience on the quest to discover the world of data.</p>
				</li>
				<li><a href="http://localhost:4000/about/"><span class="btn btn-inverse">Learn More</span></a></li>
				<li>
					<a href="mailto:stephanosterburg@me.com"><i class="fa fa-fw fa-envelope"></i> Email</a>
				</li>
				<li>
					<a href="https://twitter.com/sosterburg"><i class="fa fa-fw fa-twitter"></i> Twitter</a>
				</li>
				
				
				<li>
					<a href="https://linkedin.com/in/https://www.linkedin.com/in/stephanosterburg"><i class="fa fa-fw fa-linkedin"></i> LinkedIn</a>
				</li>
				<li>
					<a href="https://github.com/https://github.com/osterburg"><i class="fa fa-fw fa-github"></i> GitHub</a>
				</li>
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="http://localhost:4000/posts/">All Posts</a></li>
				<li><a href="http://localhost:4000/tags/">All Tags</a></li>
			</ul>
		</li>
		
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->


<div class="entry-header">
  
  
    <div class="entry-image">
      <img src="http://localhost:4000/images/background.jpeg" alt="Thoughts">
    </div><!-- /.entry-image -->
  
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>Data Ocean</h1>
      <h2>Thoughts</h2>
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->

<div id="main" role="main">
  
<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="http://localhost:4000/forest/" title="Forest Cover Type"><img src="http://localhost:4000/images/dataset-cover.jpeg" alt="Forest Cover Type"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2019-01-14T00:00:00+00:00"><a href="http://localhost:4000/forest/">January 14, 2019</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Stephan Osterburg">Stephan Osterburg</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~6 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/forest/" rel="bookmark" title="Forest Cover Type" itemprop="url">Forest Cover Type</a></h1>
    
  </header>
  <div class="entry-content">
    <h2 id="or-who-cannot-see-the-wood-for-the-trees">Or who cannot see the wood for the trees?</h2>

<p>Researchers at the Department of Forest Sciences at Colorado State University collected over half a million measurements from tree observations from four areas of the Roosevelt National Forest in Colorado. All observations are cartographic variables (no remote sensing) from 30-meter x 30-meter sections of forest.</p>

<p>The resulting dataset includes information on tree type, shadow coverage, distance to nearby landmarks (roads etcetera), soil type, and local topography. In total there are 55 columns/features.</p>

<h3 id="problem">Problem</h3>

<p>Can we build a model that predicts what types of trees grow in an area based on the surrounding characteristics? Like elevation, slope, distance, soil type etcetera.</p>

<h3 id="dataset">Dataset</h3>

<p>The dataset has 55 columns in total where <code class="highlighter-rouge">Wilderness_Area</code> consists of 4 dummy variables and <code class="highlighter-rouge">Soil_Tpye</code> consists of 40 dummy variables.</p>

<p>Continuous Data</p>
<ul>
  <li><code class="highlighter-rouge">Elevation</code> (in meters)</li>
  <li><code class="highlighter-rouge">Aspect</code> (in degrees azimuth<sup id="fnref:2"><a href="#fn:2" class="footnote">1</a></sup>)</li>
  <li><code class="highlighter-rouge">Slope</code> (in degrees)</li>
  <li><code class="highlighter-rouge">Horizontal_Distance_To_Hydrology</code> (Horizontal distance to nearest surface water features in meters)</li>
  <li><code class="highlighter-rouge">Horizontal_Distance_To_Roadways</code> (Horizontal distance to nearest roadway in meters)</li>
  <li><code class="highlighter-rouge">Horizontal_Distance_To_Fire_Points</code> (Horizontal distance to nearest wildfire ignition points in meters)</li>
  <li><code class="highlighter-rouge">Vertical_Distance_To_Hydrology</code> (Vertical distance to nearest surface water features in meters)</li>
  <li><code class="highlighter-rouge">Hillshade_9am</code> (Hill shade index at 9am, summer solstice. Value out of 255)</li>
  <li><code class="highlighter-rouge">Hillshade_Noon</code> (Hill shade index at noon, summer solstice. Value out of 255)</li>
  <li><code class="highlighter-rouge">Hillshade_3pm</code> (Hill shade index at 3pm, summer solstice. Value out of 255)</li>
</ul>

<p>Categorical Data</p>
<ul>
  <li><code class="highlighter-rouge">Wilderness Area</code> (4 dummy variable binary columns, 0 = absence or 1 = presence)</li>
  <li><code class="highlighter-rouge">Soil Type</code> (40 dummy variable binary columns, 0 = absence or 1 = presence)</li>
</ul>

<p>The target variable <code class="highlighter-rouge">Cover_Type</code> is defined as an integer value between <code class="highlighter-rouge">1</code> and <code class="highlighter-rouge">7</code>, with the following key:</p>

<ol>
  <li>Spruce/Fir.</li>
  <li>Lodgepole Pine.</li>
  <li>Ponderosa Pine.</li>
  <li>Cottonwood/Willow</li>
  <li>Aspen</li>
  <li>Douglas-fir</li>
  <li>Krummholz</li>
</ol>

<h3 id="approach">Approach</h3>

<h4 id="eda">EDA</h4>

<p>The first step with every dataset is to do an <code class="highlighter-rouge">Exploratory Data Analysis</code> (EDA). What kind of data do we have? Text or numerical (continues or categorical)? Do we have missing data, or just merely wrong data — values which do not make any sense in the given context, i.e., 9999.</p>

<p>Because of the sheer number of soil types and wilderness areas I had a look at them first. Luckily, the researchers here were efficient in the sense that they document everything meticulously. Everything we need to know with a detailed description can be found online<sup id="fnref:3"><a href="#fn:3" class="footnote">2</a></sup>.</p>

<p>From that document, we can find out that</p>
<blockquote>
  <p>This study area includes four wilderness areas located in the
   Roosevelt National Forest of northern Colorado.  These areas
   represent forests with minimal human-caused disturbances,
   so that existing forest cover types are more a result of 
   ecological processes rather than forest management practices.</p>
</blockquote>

<p>Not that this is of any importance for our data exploration or to make a prediction, but I found it interesting to read. Because it makes you think about what kind of implications your result can potentially have.</p>

<p>However, what we want to find out is how the data is distributed by <code class="highlighter-rouge">Cover_Type</code>. Here I created a <code class="highlighter-rouge">seaborn.countplot</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tmpList</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">soil_df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">tmpList</span> <span class="o">+=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">c</span><span class="p">)]</span> <span class="o">*</span> <span class="n">soil_df</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">se</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">tmpList</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">'Soil_Types'</span><span class="p">]</span> <span class="o">=</span> <span class="n">se</span><span class="o">.</span><span class="n">values</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Soil_Types'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'Cover_Type'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Number of Observation by Cover Type'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div></div>

<figure>
    
    <a href="/images/SoilType.png"><img src="/images/SoilType.png" alt="" /></a>
    
    <figcaption></figcaption>
</figure>

<p>Looking more closely at the data we can find that the top 5 soil types count for more than 50% of the measurements in the collected data.</p>

<p>Unlike categorical data, the continues data is even more interesting to investigate. The questions we want to find answers for are</p>

<ul>
  <li>Do we need to scale/normalise the continuous data?</li>
  <li>What about skewness/kurtosis?</li>
  <li>Does it matter if the data is in meter, degree or index?</li>
</ul>

<figure>
    
    <a href="/images/ContinuesData.png"><img src="/images/ContinuesData.png" alt="" /></a>
    
    <figcaption></figcaption>
</figure>

<h3 id="feature-selection">Feature Selection</h3>

<p>There are several ways to explore what features we need to keep around to make our prediction. The labour intensive workflow and the much quicker workflow - what I would like to call the “blind folded method”. For the purpose of gaining more inside, I choose to do both.</p>

<p>In the first workflow, I used several classifiers from the <code class="highlighter-rouge">sklearn.ensemble</code> Library. These are, <code class="highlighter-rouge">AdaBoostClassifier</code>,  <code class="highlighter-rouge">RandomForestClassifier</code>, <code class="highlighter-rouge">GradientBoostingClassifier</code> and <code class="highlighter-rouge">ExtraTreeClassifier</code>. All these classifiers have one thing in common, which is the attribute <code class="highlighter-rouge">feature_importances_</code>, which returns the feature importance (the higher the value, the more important the feature).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create an empty dataframe to hold our findings for feature_importances_
</span><span class="n">ranking_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>

<span class="n">RFC_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">RFC_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">importances</span> <span class="o">=</span> <span class="n">RFC_model</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">importances</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Get feature name
</span><span class="n">rfc_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">f</span><span class="p">]]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
<span class="n">ranking_df</span><span class="p">[</span><span class="s">'RFC'</span><span class="p">]</span> <span class="o">=</span> <span class="n">rfc_list</span>

<span class="c1"># Get feature importance
</span><span class="n">rfci_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">importances</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">f</span><span class="p">]]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
<span class="n">ranking_df</span><span class="p">[</span><span class="s">'RFC importance'</span><span class="p">]</span> <span class="o">=</span> <span class="n">rfci_list</span>
</code></pre></div></div>

<p>The result was a pandas data frame with all features from the dataset in order of importance, which allows us to pick the best features. Interestingly, <code class="highlighter-rouge">RandomForestClassifier</code> and <code class="highlighter-rouge">ExtraTreeClassifier</code> had the most similar results. Other findings from that list were,</p>

<ul>
  <li><code class="highlighter-rouge">Gradian Boosting</code> shows similar names just in a different order compared to <code class="highlighter-rouge">Random Forest</code> and <code class="highlighter-rouge">Extra Tree</code>.</li>
  <li><code class="highlighter-rouge">AdaBoost</code> on the other hand shows an exciting and unique result. The top 8 features alone are enough to make a good class prediction. Compared to all the other classifiers, here we have <code class="highlighter-rouge">Wilderness_Area4</code> on above <code class="highlighter-rouge">Elevation</code> in the list.</li>
  <li><code class="highlighter-rouge">Elevation</code> dominates in all classifiers with a range of <code class="highlighter-rouge">18-25%</code>, up to <code class="highlighter-rouge">65%</code> in <code class="highlighter-rouge">GBC</code>.</li>
  <li><code class="highlighter-rouge">Hillshade</code> features are seen in the top 20 in 3 out of 4 classifiers. <code class="highlighter-rouge">Random Forest</code> and <code class="highlighter-rouge">Extra Tree Classifier</code> show <code class="highlighter-rouge">Hillshade</code> features having similar ranges.</li>
  <li><code class="highlighter-rouge">Horizontal_Distance_To_Hydrology</code> and <code class="highlighter-rouge">Vertical_Distance_To_Hydrology</code> are in all classifiers in the top 10.</li>
  <li><code class="highlighter-rouge">Horizontal_Distance_To_Roadways</code> and <code class="highlighter-rouge">Horizontal_Distance_To_Fire_Points</code> are represented at the top 3 out of 4 classifiers.</li>
  <li><code class="highlighter-rouge">Aspect</code> and <code class="highlighter-rouge">Slope</code> also show up in the top 20 across all classifiers, with the exception of Gradian Boosting Slope which isn’t in the top 20.</li>
  <li>In regards to <code class="highlighter-rouge">Soil_Type</code>, it is hard to find some commonality. Here I choose to select: <code class="highlighter-rouge">Soil_Type2</code>, <code class="highlighter-rouge">Soil_Type4</code>, <code class="highlighter-rouge">Soil_Type10</code>, <code class="highlighter-rouge">Soil_Type22</code>, <code class="highlighter-rouge">Soil_Type23</code> and <code class="highlighter-rouge">Soil_Type39</code>.</li>
</ul>

<p>The question I asked myself at this point is, was the time wisely spend? After all, it took almost 20 minutes to calculate. One advantage this approach has is, we know our selected features.</p>

<p>The other approach we can choose is using <code class="highlighter-rouge">PCA</code> (Principal Component Analysis) from sklearn.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'Cover_Type'</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'Cover_Type'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
</code></pre></div></div>

<p>The big advantage to this is the short processing time. But the drawback, we are losing any knowledge regarding our features. Now is that important? Maybe.</p>

<h3 id="evaluate-model">Evaluate Model</h3>

<p>By hand selecting our features, we get an <code class="highlighter-rouge">accuracy of 92.23%</code> and an <code class="highlighter-rouge">f1_score of 86.74%</code> using cross validation. In contrast, <code class="highlighter-rouge">PCA</code> has an <code class="highlighter-rouge">accuracy of 90.72%</code> and an <code class="highlighter-rouge">f1_score of 84.44%</code>. Is that a big enough difference to justify the time spent to find our features? Maybe.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_pca</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s">'distance'</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s">'accuracy'</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">f1_score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s">'f1_macro'</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># predict
</span><span class="n">predict</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># calculating accuracy
</span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predict</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'KNeighbors Classifier model'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy: {:.2f}</span><span class="si">%</span><span class="s">'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>

<span class="n">knn_classification_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predict</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">knn_classification_report</span><span class="p">)</span>
</code></pre></div></div>

<figure>
    
    <a href="/images/CrossValidation.png"><img src="/images/CrossValidation.png" alt="" /></a>
    
    <figcaption></figcaption>
</figure>

<p>To test how accurate we can predict the <code class="highlighter-rouge">Cover_Type</code> I used the <code class="highlighter-rouge">KNeighborsClassifier</code> from sklearn, and we got an accuracy of <code class="highlighter-rouge">91.02%</code>. That is great.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Yes, we can build a model that predicts what types of trees grow in an area based on the surrounding characteristics.</p>

<h2 id="final-thought">Final Thought</h2>

<p>We can use sklearn’s <code class="highlighter-rouge">GridSearchCV</code> to find our features (exhaustive search over specified parameter values for an estimator). Moreover, we should make use of sklearn’s <code class="highlighter-rouge">Pipeline</code> functionality to write clean and manageable code.</p>

<h5 id="footnotes">Footnotes</h5>

<noscript><pre>404: Not Found
</pre></noscript>
<script src="https://gist.github.com/mmistakes/6589546.js"> </script>

<div class="footnotes">
  <ol>
    <li id="fn:2">
      <p><a href="https://en.wikipedia.org/wiki/Azimuth">https://en.wikipedia.org/wiki/Azimuth</a> <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p><a href="https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info">https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info</a> <a href="#fnref:3" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="http://localhost:4000/why/" title="“Why did you decide to learn data science?”"><img src="http://localhost:4000/images/Tokyo.png" alt="“Why did you decide to learn data science?”"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2018-12-05T00:00:00+00:00"><a href="http://localhost:4000/why/">December 05, 2018</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Stephan Osterburg">Stephan Osterburg</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~1 minute
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/why/" rel="bookmark" title="“Why did you decide to learn data science?”" itemprop="url">“Why did you decide to learn data science?”</a></h1>
    
  </header>
  <div class="entry-content">
    <p>I don’t remember when I came across “The Visual Display of Quantitative Information” by Edward R.Tufte<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>, but I remember that I was fascinated by it and read it in one swoop. Moreover, I just wanted to do cool visualisations. However, at that time there was no need for it.</p>

<p>Sometime in the early nineties (I believe), I saw a short film by a Japanese computer graphics company visualising all data available at that time about Tokyo. I was just fascinated by it and just wanted to do that. Still, at that time there was no real need for it. At least not in Germany.</p>

<p>Fast forward, another Edward Tufte book and much more cool things over the time, I found myself at a crossroad. Do I take the blue pill or the red pill? Because I can’t remember which tablet does what, I decided to take some time off to figure out what I would love to do next.</p>

<p>So here I am, rediscovering my fascination for data and visualisation. Looking forward to using my experience in computer graphics and combine it with the newly learned knowledge.</p>

<noscript><pre>404: Not Found
</pre></noscript>
<script src="https://gist.github.com/mmistakes/6589546.js"> </script>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p><a href="https://www.edwardtufte.com/tufte/books_vdqi">https://www.edwardtufte.com/tufte/books_vdqi</a> <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->



</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2019 Stephan Osterburg. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="https://mademistakes.com/work/hpstr-jekyll-theme/" rel="nofollow">HPSTR Theme</a>.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>



          

</body>
</html>